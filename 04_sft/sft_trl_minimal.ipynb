{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71690f4b",
   "metadata": {},
   "source": [
    "# Instruction Fine-tuning – TRL SFTTrainer + PEFT/LoRA (EN/VN)\n",
    "**Objective/Mục tiêu**: Run a minimal SFT loop on a tiny instruction dataset. Evaluate before/after on a few prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fddcc6",
   "metadata": {},
   "source": [
    "\n",
    "# !pip install -q transformers datasets accelerate peft trl bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, random, os\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# Tiny synthetic instruction dataset (replace with your own later)\n",
    "samples = [\n",
    "    {\"instruction\": \"Extract cities from the text.\", \"input\": \"Hanoi, Bangkok, and Singapore are major cities.\", \"output\": '[\"Hanoi\",\"Bangkok\",\"Singapore\"]'},\n",
    "    {\"instruction\": \"Translate to English.\", \"input\": \"Xin chào, tôi là sinh viên.\", \"output\": \"Hello, I am a student.\"},\n",
    "    {\"instruction\": \"Summarize in 1 sentence.\", \"input\": \"Large language models are useful but can hallucinate.\", \"output\": \"LLMs are powerful yet prone to hallucinations.\"},\n",
    "]\n",
    "# Expand a bit\n",
    "samples = samples * 200\n",
    "random.shuffle(samples)\n",
    "\n",
    "def format_example(ex):\n",
    "    return f\"### Instruction:\n",
    "{ex['instruction']}\n",
    "\n",
    "### Input:\n",
    "{ex['input']}\n",
    "\n",
    "### Response:\n",
    "{ex['output']}\"\n",
    "\n",
    "ds = Dataset.from_dict({\"text\": [format_example(x) for x in samples]})\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "\n",
    "config = SFTConfig(\n",
    "    output_dir=\"./sft_out\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1e-4,\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_seq_length=512,\n",
    "    dataset_text_field=\"text\",\n",
    "    packing=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=ds.select(range(500)),\n",
    "    args=config\n",
    ")\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(\"./sft_out/model\")\n",
    "tokenizer.save_pretrained(\"./sft_out/model\")\n",
    "print(\"SFT finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd60832",
   "metadata": {},
   "source": [
    "\n",
    "# Quick before/after comparison utility\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "prompts = [\n",
    "    \"Extract cities from this: Hanoi and Ho Chi Minh City are in Vietnam; Vientiane is in Laos.\",\n",
    "    \"Summarize: Retrieval-augmented generation uses external documents to ground answers.\",\n",
    "]\n",
    "\n",
    "def chat(model_id):\n",
    "    tok = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "    mdl = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "    pipe = pipeline(\"text-generation\", model=mdl, tokenizer=tok, max_new_tokens=128)\n",
    "    for p in prompts:\n",
    "        out = pipe(p)[0][\"generated_text\"]\n",
    "        print(\"===\", model_id, \"===\"); print(p); print(out, \"\n",
    "\")\n",
    "\n",
    "print(\"Baseline (pretrained):\")\n",
    "chat(\"Qwen/Qwen2.5-0.5B-Instruct\")\n",
    "\n",
    "print(\"After SFT:\")\n",
    "chat(\"./sft_out/model\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
